{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f265e2",
   "metadata": {},
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f96a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as rqt\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5b8139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WikipediaThe Free Encyclopedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 000 000+articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100 000+articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 000+articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 000+articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100+articles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Headers\n",
       "0  WikipediaThe Free Encyclopedia\n",
       "1              1 000 000+articles\n",
       "2                100 000+articles\n",
       "3                 10 000+articles\n",
       "4                  1 000+articles\n",
       "5                    100+articles"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def header(url):\n",
    "    page=rqt.get(url)\n",
    "    print(page)\n",
    "    data=BeautifulSoup(page.content)\n",
    "    header=data.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "    pattern=re.compile(r'\\n')\n",
    "    headings=[]\n",
    "    for i in header:\n",
    "        headings.append(pattern.sub('',str(i.text)))\n",
    "    df=pd.DataFrame({'Headers':headings})\n",
    "    return df\n",
    "        \n",
    "        \n",
    "header('https://www.wikipedia.org/')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929bbb9",
   "metadata": {},
   "source": [
    "# 2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55d89eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of President</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>14th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>13th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>12th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>11th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>10th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>9th  President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>8th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>7th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>6th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>5th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>4th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>3rd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>2nd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>1st President of India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name of President           Term of Office\n",
       "0           Shri Ram Nath Kovind  14th President of India\n",
       "1          Shri Pranab Mukherjee  13th President of India\n",
       "2   Smt Pratibha Devisingh Patil  12th President of India\n",
       "3         DR. A.P.J. Abdul Kalam  11th President of India\n",
       "4           Shri K. R. Narayanan  10th President of India\n",
       "5        Dr Shankar Dayal Sharma  9th  President of India\n",
       "6            Shri R Venkataraman   8th President of India\n",
       "7               Giani Zail Singh   7th President of India\n",
       "8      Shri Neelam Sanjiva Reddy   6th President of India\n",
       "9       Dr. Fakhruddin Ali Ahmed   5th President of India\n",
       "10  Shri Varahagiri Venkata Giri   4th President of India\n",
       "11              Dr. Zakir Husain   3rd President of India\n",
       "12  Dr. Sarvepalli Radhakrishnan   2nd President of India\n",
       "13           Dr. Rajendra Prasad   1st President of India"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPresidents(url):\n",
    "    page=rqt.get(url)\n",
    "    data=BeautifulSoup(page.content)\n",
    "    presidents=data.find_all('h3')\n",
    "    l=[]\n",
    "    for i in presidents:\n",
    "        l.append(re.sub(r'/[|/]','',i.text))\n",
    "    presidents_o=data.find_all('h5')\n",
    "    term=[]\n",
    "    for i in presidents_o:\n",
    "        term.append(re.sub(r'/[|/]','',i.text))\n",
    "    df=pd.DataFrame({'Name of President':l,'Term of Office':term})\n",
    "    return df\n",
    "\n",
    "\n",
    "        \n",
    "getPresidents('https://presidentofindia.nic.in/former-presidents')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25331ff",
   "metadata": {},
   "source": [
    "# 3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\u0002a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ac187549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CricketDetails:\n",
    "    \n",
    "    \n",
    "    def odiTop10Teams(self,url):\n",
    "    \n",
    "        page=rqt.get(url)\n",
    "        soup=BeautifulSoup(page.content)\n",
    "        odi_teams=[]\n",
    "        odi_teams.clear()\n",
    "        matchs=[]\n",
    "        matchs.clear()\n",
    "        points=[]\n",
    "        points.clear()\n",
    "        rank=[]\n",
    "        rank.clear()\n",
    "        \n",
    "        #*************************************************************************************************************\n",
    "        #scraping baner data\n",
    "        banner_team_matches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "        matchs.append(banner_team_matches.text)\n",
    "        banner_team_points=soup.find('td',class_='rankings-block__banner--points')\n",
    "        points.append(banner_team_points.text)\n",
    "        banner_team_rating=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "        pattern=re.compile(r'[0-9]{3}')\n",
    "        r=pattern.findall(str(banner_team_rating))\n",
    "        rank.append(r[0])\n",
    "        #*************************************************************************************************************\n",
    "        #scraping table data\n",
    "        table_teams=soup.find_all('span',class_='u-hide-phablet')\n",
    "        for i in table_teams:\n",
    "            odi_teams.append(i.text)\n",
    "        table_matches=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "        for j in range(0,len(table_matches)-1,2):\n",
    "            matchs.append(table_matches[j].text)\n",
    "            points.append(table_matches[j+1].text)\n",
    "        table_rating=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "        for k in table_rating:\n",
    "            rank.append(k.text)\n",
    "        #*************************************************************************************************************\n",
    "        #creating dataframe\n",
    "        Rank=[i for i in range(1,20)]\n",
    "\n",
    "        ODI_POINTS_TABLE=pd.DataFrame({'Rank':Rank,'Team':odi_teams,'Matchs':matchs,'Points':points,'Rating':rank},index=None)\n",
    "        print('TOP 10 TEAMS IN ODI RANKING')\n",
    "        return ODI_POINTS_TABLE.head(10)\n",
    "\n",
    "    \n",
    "        \n",
    "    def odiTop10Batsmen(self,url):\n",
    "        batsmenName=[]\n",
    "        batsmenName.clear()\n",
    "        teamName=[]\n",
    "        teamName.clear()\n",
    "        playerRating=[]\n",
    "        playerRating.clear()\n",
    "        playerRecord=[]\n",
    "        playerRecord.clear()\n",
    "        #*********************************************************************************\n",
    "        #sending request to webpage and loading content\n",
    "        page=rqt.get(url)\n",
    "        soup=BeautifulSoup(page.content)\n",
    "        #**********************************************************************************\n",
    "        #banner records\n",
    "        bannerName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "        batsmenName.append(bannerName.text)\n",
    "        '------------------------------------------------------------------------'\n",
    "        team=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "        pattern=re.compile(r'\\n')\n",
    "        teamName.append(pattern.sub('',str(team.text)))\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "        playerRating.append(rating.text)\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rec=soup.find('span',class_='rankings-block__career-best-text')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        playerRecord.append(pattern.sub('',str(rec.text)))\n",
    "        #***********************************************************************************\n",
    "        #scrapiing table data\n",
    "        name=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "        pattern=re.compile(r'\\n+')\n",
    "        for i in name:\n",
    "            batsmenName.append(pattern.sub('',str(i.text)))\n",
    "        #**************************************************\n",
    "        name=soup.find_all('span',class_='table-body__logo-text')\n",
    "        \n",
    "        for i in name:\n",
    "            teamName.append(i.text)\n",
    "        #**************************************************************\n",
    "        \n",
    "        name=soup.find_all('td',class_='table-body__cell rating')\n",
    "        for i in name:\n",
    "            playerRating.append(i.text)\n",
    "        #****************************************************************\n",
    "        name=soup.find_all('td',class_='table-body__cell u-text-right u-hide-phablet')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        #pattern.sub('',str(i.text))\n",
    "        for i in name:\n",
    "            playerRecord.append(pattern.sub('',str(i.text)))\n",
    "        #**********************************************************************\n",
    "        #creating dataframe\n",
    "        Rank2=[i for i in range(1,101)]\n",
    "        bat= pd.DataFrame({'Rank':Rank2,'Name':batsmenName,'Team':teamName,'Rating':playerRating,'Best Records':playerRecord},index=None)\n",
    "        print('TOP 10 BATSMEN IN ODI RANKING')\n",
    "        return bat.head(10)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def odiTop10Bowler(self,url):\n",
    "        bowlerName=[]\n",
    "        bowlerName.clear()\n",
    "        teamName=[]\n",
    "        teamName.clear()\n",
    "        playerRating=[]\n",
    "        playerRating.clear()\n",
    "        playerRecord=[]\n",
    "        playerRecord.clear()\n",
    "        #*********************************************************************************\n",
    "        #sending request to webpage and loading content\n",
    "        page=rqt.get(url)\n",
    "        soup=BeautifulSoup(page.content)\n",
    "        #**********************************************************************************\n",
    "        #banner records\n",
    "        bowlerName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "#         bowlerName.append(bannerName.text)\n",
    "        '------------------------------------------------------------------------'\n",
    "        team=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "        pattern=re.compile(r'\\n')\n",
    "        teamName.append(pattern.sub('',str(team.text)))\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "        playerRating.append(rating.text)\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rec=soup.find('span',class_='rankings-block__career-best-text')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        playerRecord.append(pattern.sub('',str(rec.text)))\n",
    "        #***********************************************************************************\n",
    "        #scrapiing table data\n",
    "        name=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "        pattern=re.compile(r'\\n+')\n",
    "        for i in name:\n",
    "            bowlerName.append(pattern.sub('',str(i.text)))\n",
    "        #**************************************************\n",
    "        name=soup.find_all('span',class_='table-body__logo-text')\n",
    "        \n",
    "        for i in name:\n",
    "            teamName.append(i.text)\n",
    "        #**************************************************************\n",
    "        \n",
    "        name=soup.find_all('td',class_='table-body__cell rating')\n",
    "        for i in name:\n",
    "            playerRating.append(i.text)\n",
    "        #****************************************************************\n",
    "        name=soup.find_all('td',class_='table-body__cell u-text-right u-hide-phablet')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        for i in name:\n",
    "            playerRecord.append(pattern.sub('',str(i.text)))\n",
    "        #**********************************************************************\n",
    "        #creating datframe\n",
    "        Rank3=[i for i in range(1,101)]\n",
    "        bowling= pd.DataFrame({\"Rank\":Rank3,'Name':bowlerName,'Team':teamName,'Rating':playerRating,'Best Records':playerRecord},index=None)\n",
    "        print('TOP 10 BOWLERS IN ODI RANKING')\n",
    "        return bowling.head(10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6b3f52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 TEAMS IN ODI RANKING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matchs</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>23</td>\n",
       "      <td>2,714</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>2,316</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>India</td>\n",
       "      <td>36</td>\n",
       "      <td>4,081</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>27</td>\n",
       "      <td>2,806</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>England</td>\n",
       "      <td>24</td>\n",
       "      <td>2,426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>1,910</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>28</td>\n",
       "      <td>2,661</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>16</td>\n",
       "      <td>1,404</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>32</td>\n",
       "      <td>2,794</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank          Team Matchs Points Rating\n",
       "0     1     Australia     23  2,714    118\n",
       "1     2      Pakistan     20  2,316    116\n",
       "2     3         India     36  4,081    113\n",
       "3     4   New Zealand     27  2,806    104\n",
       "4     5       England     24  2,426    101\n",
       "5     6  South Africa     19  1,910    101\n",
       "6     7    Bangladesh     28  2,661     95\n",
       "7     8   Afghanistan     16  1,404     88\n",
       "8     9     Sri Lanka     32  2,794     87\n",
       "9    10   West Indies     38  2,582     68"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob=CricketDetails()\n",
    "ob.odiTop10Teams('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9adbabd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 BATSMEN IN ODI RANKING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Best Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>886</td>\n",
       "      <td>898vWestIndies,10/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>777</td>\n",
       "      <td>796vEngland,19/07/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>755</td>\n",
       "      <td>784vNewZealand,29/04/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>745</td>\n",
       "      <td>815vWestIndies,12/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>743</td>\n",
       "      <td>743vWestIndies,01/08/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>726</td>\n",
       "      <td>726vNepal,04/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>726</td>\n",
       "      <td>880vPakistan,26/01/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>718</td>\n",
       "      <td>813vSriLanka,10/03/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>705</td>\n",
       "      <td>911vEngland,12/07/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "      <td>752vPakistan,22/01/2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                   Name                     Team Rating  \\\n",
       "0     1             Babar Azam  PAK                        886   \n",
       "1     2  Rassie van der Dussen                       SA    777   \n",
       "2     3           Fakhar Zaman                      PAK    755   \n",
       "3     4            Imam-ul-Haq                      PAK    745   \n",
       "4     5           Shubman Gill                      IND    743   \n",
       "5     6           Harry Tector                      IRE    726   \n",
       "6     7           David Warner                      AUS    726   \n",
       "7     8        Quinton de Kock                       SA    718   \n",
       "8     9            Virat Kohli                      IND    705   \n",
       "9    10            Steve Smith                      AUS    702   \n",
       "\n",
       "                Best Records  \n",
       "0  898vWestIndies,10/06/2022  \n",
       "1     796vEngland,19/07/2022  \n",
       "2  784vNewZealand,29/04/2023  \n",
       "3  815vWestIndies,12/06/2022  \n",
       "4  743vWestIndies,01/08/2023  \n",
       "5       726vNepal,04/07/2023  \n",
       "6    880vPakistan,26/01/2017  \n",
       "7    813vSriLanka,10/03/2019  \n",
       "8     911vEngland,12/07/2018  \n",
       "9    752vPakistan,22/01/2017  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob.odiTop10Batsmen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "af85d9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 BOWLERS IN ODI RANKING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Best Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>705</td>\n",
       "      <td>733vEngland,26/01/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "      <td>783vNewZealand,29/03/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>682</td>\n",
       "      <td>806vPakistan,21/09/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>670</td>\n",
       "      <td>736vNewZealand,21/01/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>667</td>\n",
       "      <td>691vBangladesh,26/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>661</td>\n",
       "      <td>712vIreland,24/01/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>660</td>\n",
       "      <td>775vAustralia,11/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "      <td>655vEngland,22/11/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>630</td>\n",
       "      <td>688vWestIndies,10/06/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>IND</td>\n",
       "      <td>622</td>\n",
       "      <td>765vNewZealand,26/01/2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank              Name                     Team Rating  \\\n",
       "0     1    Josh Hazlewood  AUS                        705   \n",
       "1     2    Mitchell Starc                      AUS    686   \n",
       "2     3       Rashid Khan                      AFG    682   \n",
       "3     4    Mohammed Siraj                      IND    670   \n",
       "4     5        Matt Henry                       NZ    667   \n",
       "5     6  Mujeeb Ur Rahman                      AFG    661   \n",
       "6     7       Trent Boult                       NZ    660   \n",
       "7     8        Adam Zampa                      AUS    652   \n",
       "8     9    Shaheen Afridi                      PAK    630   \n",
       "9    10     Kuldeep Yadav                      IND    622   \n",
       "\n",
       "                Best Records  \n",
       "0     733vEngland,26/01/2018  \n",
       "1  783vNewZealand,29/03/2015  \n",
       "2    806vPakistan,21/09/2018  \n",
       "3  736vNewZealand,21/01/2023  \n",
       "4  691vBangladesh,26/03/2021  \n",
       "5     712vIreland,24/01/2021  \n",
       "6   775vAustralia,11/09/2022  \n",
       "7     655vEngland,22/11/2022  \n",
       "8  688vWestIndies,10/06/2022  \n",
       "9  765vNewZealand,26/01/2019  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ob.odiTop10Bowler('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e1494",
   "metadata": {},
   "source": [
    "# 4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\u0002\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "25e07b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class womensCricket:\n",
    "    \n",
    "    \n",
    "    def womentsTop10OdiTeams(self,url):\n",
    "        page=rqt.get(url)\n",
    "        soup=BeautifulSoup(page.content)\n",
    "        odi_teams=[]\n",
    "        odi_teams.clear()\n",
    "        matchs=[]\n",
    "        matchs.clear()\n",
    "        points=[]\n",
    "        points.clear()\n",
    "        rank=[]\n",
    "        rank.clear()\n",
    "\n",
    "        #*************************************************************************************************************\n",
    "        #scraping baner data\n",
    "        banner_team_matches=soup.find('td',class_='rankings-block__banner--matches')\n",
    "        matchs.append(banner_team_matches.text)\n",
    "        banner_team_points=soup.find('td',class_='rankings-block__banner--points')\n",
    "        points.append(banner_team_points.text)\n",
    "        banner_team_rating=soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "        pattern=re.compile(r'[0-9]{3}')\n",
    "        r=pattern.findall(str(banner_team_rating))\n",
    "        rank.append(r[0])\n",
    "        #*************************************************************************************************************\n",
    "        #scraping table data\n",
    "        table_teams=soup.find_all('span',class_='u-hide-phablet')\n",
    "        for i in table_teams:\n",
    "            odi_teams.append(i.text)\n",
    "        table_matches=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "        for j in range(0,len(table_matches)-1,2):\n",
    "            matchs.append(table_matches[j].text)\n",
    "            points.append(table_matches[j+1].text)\n",
    "        table_rating=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "        for k in table_rating:\n",
    "            rank.append(k.text)\n",
    "        #*************************************************************************************************************\n",
    "        #creating dataframe\n",
    "        Rank=[i for i in range(1,14)]\n",
    "        ODI_POINTS_TABLE=pd.DataFrame({'Rank':Rank,'Team':odi_teams,'Matchs':matchs,'Points':points,'Rating':rank},index=None)\n",
    "        print('TOP 10 TEAMS IN WOMENS ODI RANKING')\n",
    "        return ODI_POINTS_TABLE.head(10)\n",
    "    \n",
    "    def Top10OdiBatWomens(self,url):\n",
    "        batsmenName=[]\n",
    "        batsmenName.clear()\n",
    "        teamName=[]\n",
    "        teamName.clear()\n",
    "        playerRating=[]\n",
    "        playerRating.clear()\n",
    "        playerRecord=[]\n",
    "        playerRecord.clear()\n",
    "        #*********************************************************************************\n",
    "        #sending request to webpage and loading content\n",
    "        page=rqt.get(url)\n",
    "        soup=BeautifulSoup(page.content)\n",
    "        #**********************************************************************************\n",
    "        #banner records\n",
    "        bannerName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "        batsmenName.append(bannerName.text)\n",
    "        '------------------------------------------------------------------------'\n",
    "        team=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "        pattern=re.compile(r'\\n')\n",
    "        teamName.append(pattern.sub('',str(team.text)))\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "        playerRating.append(rating.text)\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rec=soup.find('span',class_='rankings-block__career-best-text')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        playerRecord.append(pattern.sub('',str(rec.text)))\n",
    "        #***********************************************************************************\n",
    "        #scrapiing table data\n",
    "        name=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "        pattern=re.compile(r'\\n+')\n",
    "        for i in name:\n",
    "            batsmenName.append(pattern.sub('',str(i.text)))\n",
    "        #**************************************************\n",
    "        name=soup.find_all('span',class_='table-body__logo-text')\n",
    "        \n",
    "        for i in name:\n",
    "            teamName.append(i.text)\n",
    "        #**************************************************************\n",
    "        \n",
    "        name=soup.find_all('td',class_='table-body__cell rating')\n",
    "        for i in name:\n",
    "            playerRating.append(i.text)\n",
    "        #****************************************************************\n",
    "        name=soup.find_all('td',class_='table-body__cell u-text-right u-hide-phablet')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        #pattern.sub('',str(i.text))\n",
    "        for i in name:\n",
    "            playerRecord.append(pattern.sub('',str(i.text)))\n",
    "        #**********************************************************************\n",
    "        #creating dataframe\n",
    "        Rank2=[i for i in range(1,101)]\n",
    "        bat= pd.DataFrame({'Rank':Rank2,'Name':batsmenName,'Team':teamName,'Rating':playerRating,'Best Records':playerRecord},index=None)\n",
    "        print('TOP 10 WOMENS IN BATTING ODI RANKING')\n",
    "        return bat.head(10)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def Top10OdiWomensAllRounder(self,url):\n",
    "        bowlerName=[]\n",
    "        bowlerName.clear()\n",
    "        teamName=[]\n",
    "        teamName.clear()\n",
    "        playerRating=[]\n",
    "        playerRating.clear()\n",
    "        playerRecord=[]\n",
    "        playerRecord.clear()\n",
    "        #*********************************************************************************\n",
    "        #sending request to webpage and loading content\n",
    "        page=rqt.get(url)\n",
    "        soup=BeautifulSoup(page.content)\n",
    "        #**********************************************************************************\n",
    "        #banner records\n",
    "        bowlerName=soup.find('div',class_='rankings-block__banner--name-large')\n",
    "#         bowlerName.append(bannerName.text)\n",
    "        '------------------------------------------------------------------------'\n",
    "        team=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "        pattern=re.compile(r'\\n')\n",
    "        teamName.append(pattern.sub('',str(team.text)))\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rating=soup.find('div',class_='rankings-block__banner--rating')\n",
    "        playerRating.append(rating.text)\n",
    "        '-------------------------------------------------------------------------'\n",
    "        rec=soup.find('span',class_='rankings-block__career-best-text')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        playerRecord.append(pattern.sub('',str(rec.text)))\n",
    "        #***********************************************************************************\n",
    "        #scrapiing table data\n",
    "        name=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "        pattern=re.compile(r'\\n+')\n",
    "        for i in name:\n",
    "            bowlerName.append(pattern.sub('',str(i.text)))\n",
    "        #**************************************************\n",
    "        name=soup.find_all('span',class_='table-body__logo-text')\n",
    "        \n",
    "        for i in name:\n",
    "            teamName.append(i.text)\n",
    "        #**************************************************************\n",
    "        \n",
    "        name=soup.find_all('td',class_='table-body__cell rating')\n",
    "        for i in name:\n",
    "            playerRating.append(i.text)\n",
    "        #****************************************************************\n",
    "        name=soup.find_all('td',class_='table-body__cell u-text-right u-hide-phablet')\n",
    "        pattern=re.compile(r'\\n|\\s')\n",
    "        for i in name:\n",
    "            playerRecord.append(pattern.sub('',str(i.text)))\n",
    "        #**********************************************************************\n",
    "        #creating datframe\n",
    "        Rank3=[i for i in range(1,21)]\n",
    "        bowling= pd.DataFrame({\"Rank\":Rank3,'Name':bowlerName,'Team':teamName,'Rating':playerRating,'Best Records':playerRecord},index=None)\n",
    "        print('TOP 10 WOMENS IN ALLROUNDER ODI RANKING')\n",
    "        return bowling.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "114a509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 TEAMS IN WOMENS ODI RANKING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matchs</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>26</td>\n",
       "      <td>4,290</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England</td>\n",
       "      <td>31</td>\n",
       "      <td>3,875</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>30</td>\n",
       "      <td>3,039</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>28</td>\n",
       "      <td>2,688</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>29</td>\n",
       "      <td>2,743</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>17</td>\n",
       "      <td>1,284</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>12</td>\n",
       "      <td>820</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>13</td>\n",
       "      <td>883</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank          Team Matchs Points Rating\n",
       "0     1     Australia     26  4,290    165\n",
       "1     2       England     31  3,875    125\n",
       "2     3  South Africa     26  3,098    119\n",
       "3     4         India     30  3,039    101\n",
       "4     5   New Zealand     28  2,688     96\n",
       "5     6   West Indies     29  2,743     95\n",
       "6     7    Bangladesh     17  1,284     76\n",
       "7     8     Sri Lanka     12    820     68\n",
       "8     9      Thailand     13    883     68\n",
       "9    10      Pakistan     27  1,678     62"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=womensCricket()\n",
    "t.womentsTop10OdiTeams('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7e5c2e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 WOMENS IN BATTING ODI RANKING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Best Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>803</td>\n",
       "      <td>803vAustralia,18/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>758</td>\n",
       "      <td>758vNewZealand,03/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>751</td>\n",
       "      <td>776vEngland,12/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "      <td>741vAustralia,22/03/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>708</td>\n",
       "      <td>797vEngland,28/02/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>702</td>\n",
       "      <td>785vEngland,03/04/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "      <td>731vEngland,21/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>686</td>\n",
       "      <td>766vWestIndies,11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>682</td>\n",
       "      <td>834vNewZealand,24/02/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>618</td>\n",
       "      <td>766vPakistan,07/07/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                  Name                     Team Rating  \\\n",
       "0     1  Natalie Sciver-Brunt  ENG                        803   \n",
       "1     2   Chamari Athapaththu                       SL    758   \n",
       "2     3           Beth Mooney                      AUS    751   \n",
       "3     4       Laura Wolvaardt                       SA    732   \n",
       "4     5       Smriti Mandhana                      IND    708   \n",
       "5     6          Alyssa Healy                      AUS    702   \n",
       "6     7      Harmanpreet Kaur                      IND    694   \n",
       "7     8          Ellyse Perry                      AUS    686   \n",
       "8     9           Meg Lanning                      AUS    682   \n",
       "9    10       Stafanie Taylor                       WI    618   \n",
       "\n",
       "                Best Records  \n",
       "0   803vAustralia,18/07/2023  \n",
       "1  758vNewZealand,03/07/2023  \n",
       "2     776vEngland,12/07/2023  \n",
       "3   741vAustralia,22/03/2022  \n",
       "4     797vEngland,28/02/2019  \n",
       "5     785vEngland,03/04/2022  \n",
       "6     731vEngland,21/09/2022  \n",
       "7  766vWestIndies,11/09/2019  \n",
       "8  834vNewZealand,24/02/2016  \n",
       "9    766vPakistan,07/07/2021  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Top10OdiBatWomens('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c1cbd3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 WOMENS IN ALLROUNDER ODI RANKING\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Best Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>421</td>\n",
       "      <td>421vAustralia,18/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>389</td>\n",
       "      <td>389vIreland,28/07/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>382</td>\n",
       "      <td>392vIreland,26/06/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "      <td>419vWestIndies,10/09/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>329</td>\n",
       "      <td>548vWestIndies,11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>328</td>\n",
       "      <td>356vWestIndies,25/09/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>312</td>\n",
       "      <td>397vSouthAfrica,09/10/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>241</td>\n",
       "      <td>308vWestIndies,11/09/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>233</td>\n",
       "      <td>305vAustralia,05/10/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>232</td>\n",
       "      <td>232vAustralia,21/01/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                  Name                     Team Rating  \\\n",
       "0     1  Natalie Sciver-Brunt  ENG                        421   \n",
       "1     2      Ashleigh Gardner                      AUS    389   \n",
       "2     3       Hayley Matthews                       WI    382   \n",
       "3     4        Marizanne Kapp                       SA    349   \n",
       "4     5          Ellyse Perry                      AUS    329   \n",
       "5     6           Amelia Kerr                       NZ    328   \n",
       "6     7         Deepti Sharma                      IND    312   \n",
       "7     8         Jess Jonassen                      AUS    241   \n",
       "8     9         Sophie Devine                       NZ    233   \n",
       "9    10              Nida Dar                      PAK    232   \n",
       "\n",
       "                 Best Records  \n",
       "0    421vAustralia,18/07/2023  \n",
       "1      389vIreland,28/07/2023  \n",
       "2      392vIreland,26/06/2023  \n",
       "3   419vWestIndies,10/09/2021  \n",
       "4   548vWestIndies,11/09/2019  \n",
       "5   356vWestIndies,25/09/2022  \n",
       "6  397vSouthAfrica,09/10/2019  \n",
       "7   308vWestIndies,11/09/2019  \n",
       "8    305vAustralia,05/10/2020  \n",
       "9    232vAustralia,21/01/2023  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Top10OdiWomensAllRounder('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5fcb8f",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "88f83eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Posted Time</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18 Min Ago</td>\n",
       "      <td>18 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/hedge-funds-bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19 Min Ago</td>\n",
       "      <td>19 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/hawaii-governo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23 Min Ago</td>\n",
       "      <td>23 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/da-seeks-march...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46 Min Ago</td>\n",
       "      <td>46 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/abortion-pill-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46 Min Ago</td>\n",
       "      <td>46 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/landing-a-job-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>47 Min Ago</td>\n",
       "      <td>47 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/aldi-to-acquir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57 Min Ago</td>\n",
       "      <td>57 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/fundstrats-tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60 Min Ago</td>\n",
       "      <td>60 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/were-adjusting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/rosenblatt-hik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/top-investors-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/fed-meeting-mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/amazon-adds-a-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/buy-treasuries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/feds-indict-pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/how-to-turn-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/needham-makes-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/margot-robbie-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/a-biotech-hedg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/cava-sweetgree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/target-pride-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/barbie-tops-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/this-stock-buy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/activists-ease...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/psychotherapis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/goldman-sachs-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/progressive-ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/us-states-with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/why-cramer-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/08/16/jennifer-hyman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Headline  Posted Time  \\\n",
       "0    18 Min Ago   18 Min Ago   \n",
       "1    19 Min Ago   19 Min Ago   \n",
       "2    23 Min Ago   23 Min Ago   \n",
       "3    46 Min Ago   46 Min Ago   \n",
       "4    46 Min Ago   46 Min Ago   \n",
       "5    47 Min Ago   47 Min Ago   \n",
       "6    57 Min Ago   57 Min Ago   \n",
       "7    60 Min Ago   60 Min Ago   \n",
       "8    1 Hour Ago   1 Hour Ago   \n",
       "9    1 Hour Ago   1 Hour Ago   \n",
       "10  2 Hours Ago  2 Hours Ago   \n",
       "11  2 Hours Ago  2 Hours Ago   \n",
       "12  2 Hours Ago  2 Hours Ago   \n",
       "13  3 Hours Ago  3 Hours Ago   \n",
       "14  3 Hours Ago  3 Hours Ago   \n",
       "15  3 Hours Ago  3 Hours Ago   \n",
       "16  3 Hours Ago  3 Hours Ago   \n",
       "17  3 Hours Ago  3 Hours Ago   \n",
       "18  3 Hours Ago  3 Hours Ago   \n",
       "19  4 Hours Ago  4 Hours Ago   \n",
       "20  4 Hours Ago  4 Hours Ago   \n",
       "21  4 Hours Ago  4 Hours Ago   \n",
       "22  4 Hours Ago  4 Hours Ago   \n",
       "23  4 Hours Ago  4 Hours Ago   \n",
       "24  4 Hours Ago  4 Hours Ago   \n",
       "25  4 Hours Ago  4 Hours Ago   \n",
       "26  5 Hours Ago  5 Hours Ago   \n",
       "27  5 Hours Ago  5 Hours Ago   \n",
       "28  5 Hours Ago  5 Hours Ago   \n",
       "29  5 Hours Ago  5 Hours Ago   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.cnbc.com/2023/08/16/hedge-funds-bo...  \n",
       "1   https://www.cnbc.com/2023/08/16/hawaii-governo...  \n",
       "2   https://www.cnbc.com/2023/08/16/da-seeks-march...  \n",
       "3   https://www.cnbc.com/2023/08/16/abortion-pill-...  \n",
       "4   https://www.cnbc.com/2023/08/16/landing-a-job-...  \n",
       "5   https://www.cnbc.com/2023/08/16/aldi-to-acquir...  \n",
       "6   https://www.cnbc.com/2023/08/16/fundstrats-tom...  \n",
       "7   https://www.cnbc.com/2023/08/16/were-adjusting...  \n",
       "8   https://www.cnbc.com/2023/08/16/rosenblatt-hik...  \n",
       "9   https://www.cnbc.com/2023/08/16/top-investors-...  \n",
       "10  https://www.cnbc.com/2023/08/16/fed-meeting-mi...  \n",
       "11  https://www.cnbc.com/2023/08/16/amazon-adds-a-...  \n",
       "12  https://www.cnbc.com/2023/08/16/buy-treasuries...  \n",
       "13  https://www.cnbc.com/2023/08/16/feds-indict-pa...  \n",
       "14  https://www.cnbc.com/2023/08/16/stocks-making-...  \n",
       "15  https://www.cnbc.com/2023/08/16/how-to-turn-yo...  \n",
       "16  https://www.cnbc.com/2023/08/16/needham-makes-...  \n",
       "17  https://www.cnbc.com/2023/08/16/margot-robbie-...  \n",
       "18  https://www.cnbc.com/2023/08/16/a-biotech-hedg...  \n",
       "19  https://www.cnbc.com/2023/08/16/cava-sweetgree...  \n",
       "20  https://www.cnbc.com/2023/08/16/target-pride-b...  \n",
       "21  https://www.cnbc.com/2023/08/16/barbie-tops-th...  \n",
       "22  https://www.cnbc.com/2023/08/16/this-stock-buy...  \n",
       "23  https://www.cnbc.com/2023/08/16/activists-ease...  \n",
       "24  https://www.cnbc.com/2023/08/16/psychotherapis...  \n",
       "25  https://www.cnbc.com/2023/08/16/goldman-sachs-...  \n",
       "26  https://www.cnbc.com/2023/08/16/progressive-ha...  \n",
       "27  https://www.cnbc.com/2023/08/16/us-states-with...  \n",
       "28  https://www.cnbc.com/2023/08/16/why-cramer-say...  \n",
       "29  https://www.cnbc.com/2023/08/16/jennifer-hyman...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def news(url):\n",
    "    page=rqt.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    headline=[]\n",
    "    links=[]\n",
    "    Time=[]\n",
    "    headlines=soup.find_all('span',class_='LatestNews-wrapper')\n",
    "    for tag in headlines:\n",
    "        headline.append(tag.text)\n",
    "    #*****************************************\n",
    "    li=soup.find_all('a',class_='LatestNews-headline')\n",
    "    for tag in li:\n",
    "        links.append(tag.get('href'))\n",
    "    #*****************************************\n",
    "    timeData=soup.find_all('time',class_='LatestNews-timestamp')\n",
    "    for i in timeData:\n",
    "        Time.append(i.text)\n",
    "    #*******************************************\n",
    "    #df\n",
    "    News=pd.DataFrame({'Headline':headline,'Posted Time':Time,'Link':links})\n",
    "    return News\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "news('https://www.cnbc.com/world/?region=world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd9b279",
   "metadata": {},
   "source": [
    "# 6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame\u0002\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published Date\n",
    "iv) Paper URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "accbdbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article Name</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Article Name  Published Date  \\\n",
       "0                                    Reward is enough    October 2021   \n",
       "1   Explanation in artificial intelligence: Insigh...   February 2019   \n",
       "2              Creativity and artificial intelligence     August 1998   \n",
       "3   Conflict-based search for optimal multi-agent ...   February 2015   \n",
       "4   Knowledge graphs as tools for explainable mach...    January 2022   \n",
       "5   Law and logic: A review from an argumentation ...    October 2015   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...     August 1999   \n",
       "7   Explaining individual predictions when feature...  September 2021   \n",
       "8       Multiple object tracking: A literature review      April 2021   \n",
       "9   A survey of inverse reinforcement learning: Ch...     August 2021   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   February 2021   \n",
       "11  Explainable AI tools for legal reasoning about...      April 2023   \n",
       "12            Hard choices in artificial intelligence   November 2021   \n",
       "13  Assessing the communication gap between AI mod...      March 2023   \n",
       "14  Explaining black-box classifiers using post-ho...        May 2021   \n",
       "15  The Hanabi challenge: A new frontier for AI re...      March 2020   \n",
       "16              Wrappers for feature subset selection   December 1997   \n",
       "17  Artificial cognition for social human–robot in...       June 2017   \n",
       "18  A review of possible effects of cognitive bias...       June 2021   \n",
       "19  The multifaceted impact of Ada Lovelace in the...       June 2016   \n",
       "20  Robot ethics: Mapping the issues for a mechani...      April 2011   \n",
       "21          Reward (Mis)design for autonomous driving      March 2023   \n",
       "22  Planning and acting in partially observable st...        May 1998   \n",
       "23  What do we want from Explainable Artificial In...       July 2021   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=rqt.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup=BeautifulSoup(page.content)\n",
    "articals=soup.find_all('h2',class_='sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg')\n",
    "Articles=[]\n",
    "for i in articals:\n",
    "    Articles.append(i.text)\n",
    "dates=soup.find_all('span',class_='sc-1thf9ly-2 dvggWt')\n",
    "Date=[]\n",
    "for i in dates:\n",
    "    Date.append(i.text)\n",
    "links=soup.find_all('li',class_='sc-9zxyh7-1 sc-9zxyh7-2 kOEIEO hvoVxs')\n",
    "link=[]\n",
    "for i in links:\n",
    "    link.append(i.a['href'])\n",
    "#********************************************************************************************\n",
    "#creating DataFrame\n",
    "Frame=pd.DataFrame({'Article Name':Articles,'Published Date':Date,'Link':link})\n",
    "Frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c99937",
   "metadata": {},
   "source": [
    "# 7) Write a python program to scrape mentioned details from dineout.co.inand make data frame\u0002\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dc19bcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ohris Jiva Imperia</td>\n",
       "      <td>[North, Indian, Chinese, Rajasthani, South, In...</td>\n",
       "      <td>White House,Begumpet, Secunderabad</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So. The Sky Kitchen</td>\n",
       "      <td>[North, Indian, Chinese, Asian, Mughlai]</td>\n",
       "      <td>Aryan's Building,Jubilee Hills, Central West H...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exotica</td>\n",
       "      <td>[North, Indian, Chinese, Asian]</td>\n",
       "      <td>12th Square Building,Banjara Hills, Central Ea...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flechazo</td>\n",
       "      <td>[North, Indian, Italian, Mangalorean, Mediterr...</td>\n",
       "      <td>Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By The Bay - Bar Exchange</td>\n",
       "      <td>[North, Indian, Continental, Chinese]</td>\n",
       "      <td>Khairatabad, Central Hyderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Verandah</td>\n",
       "      <td>[Chinese, North, Indian, Continental, Italian]</td>\n",
       "      <td>The Park,Somajiguda, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Parampara - Flavours of india</td>\n",
       "      <td>[Chinese, North, Indian]</td>\n",
       "      <td>ANR Center,Banjara Hills, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Krishnapatnam</td>\n",
       "      <td>[Andhra, South, Indian, North, Indian]</td>\n",
       "      <td>Shreshta Aura,Jubilee Hills, Central West Hyde...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>[Pizza, Fast, Food]</td>\n",
       "      <td>The Grand Building,Somajiguda, Central East Hy...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Headquarters</td>\n",
       "      <td>[North, Indian, Italian, Chinese, Continental,...</td>\n",
       "      <td>Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Seven Spices</td>\n",
       "      <td>[Andhra, Biryani]</td>\n",
       "      <td>Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10 Downing Street</td>\n",
       "      <td>[Finger, Food, Chinese, Continental, North, In...</td>\n",
       "      <td>Begumpet, Secunderabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Eagles Pizza</td>\n",
       "      <td>[Pizza, Fast, Food]</td>\n",
       "      <td>Ohud Building,Somajiguda, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kuchipudi</td>\n",
       "      <td>[Andhra, North, Indian]</td>\n",
       "      <td>Katriya Hotel,Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hideaway</td>\n",
       "      <td>[Chinese]</td>\n",
       "      <td>Begumpet, Secunderabad</td>\n",
       "      <td>5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Urvasi Bar And Restaurant</td>\n",
       "      <td>[North, Indian, Chinese]</td>\n",
       "      <td>Hotel Urvasi,Panjagutta, Central East Hyderabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ice n Spice</td>\n",
       "      <td>[North, Indian, Continental, South, Indian, Ch...</td>\n",
       "      <td>Hotel Inner Circle,Somajiguda, Central East Hy...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amogham - The Lake View Restaurant</td>\n",
       "      <td>[Chinese, North, Indian, Continental, Mughlai]</td>\n",
       "      <td>Khairatabad, Central Hyderabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rocket Fuel Cafe</td>\n",
       "      <td>[Fast, Food]</td>\n",
       "      <td>Somajiguda, Central East Hyderabad</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>One Fine Day</td>\n",
       "      <td>[Desserts]</td>\n",
       "      <td>Necklace Road, Secunderabad</td>\n",
       "      <td>3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Gayathri Bhavan</td>\n",
       "      <td>[Chinese, Biryani]</td>\n",
       "      <td>SR Nagar, Central East Hyderabad</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Restaurant name  \\\n",
       "0                   Ohris Jiva Imperia   \n",
       "1                  So. The Sky Kitchen   \n",
       "2                              Exotica   \n",
       "3                             Flechazo   \n",
       "4            By The Bay - Bar Exchange   \n",
       "5                             Verandah   \n",
       "6        Parampara - Flavours of india   \n",
       "7                        Krishnapatnam   \n",
       "8                            Pizza Hut   \n",
       "9                         Headquarters   \n",
       "10                        Seven Spices   \n",
       "11                   10 Downing Street   \n",
       "12                        Eagles Pizza   \n",
       "13                           Kuchipudi   \n",
       "14                            Hideaway   \n",
       "15           Urvasi Bar And Restaurant   \n",
       "16                         Ice n Spice   \n",
       "17  Amogham - The Lake View Restaurant   \n",
       "18                    Rocket Fuel Cafe   \n",
       "19                        One Fine Day   \n",
       "20                     Gayathri Bhavan   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0   [North, Indian, Chinese, Rajasthani, South, In...   \n",
       "1            [North, Indian, Chinese, Asian, Mughlai]   \n",
       "2                     [North, Indian, Chinese, Asian]   \n",
       "3   [North, Indian, Italian, Mangalorean, Mediterr...   \n",
       "4               [North, Indian, Continental, Chinese]   \n",
       "5      [Chinese, North, Indian, Continental, Italian]   \n",
       "6                            [Chinese, North, Indian]   \n",
       "7              [Andhra, South, Indian, North, Indian]   \n",
       "8                                 [Pizza, Fast, Food]   \n",
       "9   [North, Indian, Italian, Chinese, Continental,...   \n",
       "10                                  [Andhra, Biryani]   \n",
       "11  [Finger, Food, Chinese, Continental, North, In...   \n",
       "12                                [Pizza, Fast, Food]   \n",
       "13                            [Andhra, North, Indian]   \n",
       "14                                          [Chinese]   \n",
       "15                           [North, Indian, Chinese]   \n",
       "16  [North, Indian, Continental, South, Indian, Ch...   \n",
       "17     [Chinese, North, Indian, Continental, Mughlai]   \n",
       "18                                       [Fast, Food]   \n",
       "19                                         [Desserts]   \n",
       "20                                 [Chinese, Biryani]   \n",
       "\n",
       "                                             Location  Ratings  \\\n",
       "0                  White House,Begumpet, Secunderabad        4   \n",
       "1   Aryan's Building,Jubilee Hills, Central West H...        4   \n",
       "2   12th Square Building,Banjara Hills, Central Ea...      4.3   \n",
       "3               Banjara Hills, Central East Hyderabad      3.6   \n",
       "4                      Khairatabad, Central Hyderabad      4.1   \n",
       "5         The Park,Somajiguda, Central East Hyderabad      3.9   \n",
       "6    ANR Center,Banjara Hills, Central East Hyderabad      3.9   \n",
       "7   Shreshta Aura,Jubilee Hills, Central West Hyde...      3.9   \n",
       "8   The Grand Building,Somajiguda, Central East Hy...      4.4   \n",
       "9                  Somajiguda, Central East Hyderabad      4.1   \n",
       "10                 Somajiguda, Central East Hyderabad      4.2   \n",
       "11                             Begumpet, Secunderabad      4.3   \n",
       "12   Ohud Building,Somajiguda, Central East Hyderabad      3.9   \n",
       "13   Katriya Hotel,Somajiguda, Central East Hyderabad        4   \n",
       "14                             Begumpet, Secunderabad        5   \n",
       "15    Hotel Urvasi,Panjagutta, Central East Hyderabad      3.9   \n",
       "16  Hotel Inner Circle,Somajiguda, Central East Hy...      4.2   \n",
       "17                     Khairatabad, Central Hyderabad      3.8   \n",
       "18                 Somajiguda, Central East Hyderabad      4.1   \n",
       "19                        Necklace Road, Secunderabad        3   \n",
       "20                   SR Nagar, Central East Hyderabad      3.6   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "13  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "14  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "15  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "16  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "17  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "18  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "19  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "20  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def restoInfo(url):\n",
    "    page=rqt.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    rName=soup.find_all('a',class_='restnt-name ellipsis')\n",
    "    restoName=[]\n",
    "    for i in rName:\n",
    "        restoName.append(i.text)\n",
    "\n",
    "    fcus=soup.find_all('span',class_='double-line-ellipsis')\n",
    "    pattern=re.compile(r'[A-Z]\\w+')\n",
    "    Cuisine=[]\n",
    "    for i in fcus:\n",
    "        Cuisine.append(pattern.findall(str(i.text)))\n",
    "\n",
    "    rName=soup.find_all('div',class_='restnt-loc ellipsis')\n",
    "    loc=[]\n",
    "    for i in rName:\n",
    "        loc.append(i.text)\n",
    "\n",
    "    rat=soup.find_all('div',class_='img-wrap')\n",
    "    Ratings=[]\n",
    "    for i in rat:\n",
    "        Ratings.append(re.sub(r'[a-z]+|[A-Z]','',i.text))\n",
    "\n",
    "    im=soup.find_all('img',class_='no-img')\n",
    "    Image=[]\n",
    "    for i in im:\n",
    "        Image.append(i['data-src'])\n",
    "        \n",
    "    dineout=pd.DataFrame({'Restaurant name':restoName,'Cuisine':Cuisine,'Location':loc,'Ratings':Ratings,'Image URL':Image})\n",
    "    return dineout\n",
    "\n",
    "    \n",
    "restoInfo(\"https://www.dineout.co.in/hyderabad-restaurants/welcome-back\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fbd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
